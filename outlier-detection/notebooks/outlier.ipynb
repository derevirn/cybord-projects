{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:fbprophet:Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D,\\\n",
    "    Dense, Layer, Reshape, InputLayer, Flatten, Input, MaxPooling2D\n",
    "from alibi_detect.od import OutlierAE\n",
    "from alibi_detect.utils.visualize import plot_instance_score, plot_feature_outlier_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 32, 32, 3) (800, 32, 32, 3) (3187, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "def img_to_np(path):  \n",
    "    img_array = []\n",
    "    fpaths = glob.glob(path)\n",
    "    for fname in fpaths:\n",
    "        img = Image.open(fname).convert(\"RGB\")\n",
    "        img = img.resize((32,32))\n",
    "        img_array.append(np.asarray(img))\n",
    "    images = np.array(img_array)\n",
    "    return images\n",
    "\n",
    "train, valid = train_test_split(img_to_np(\"D:\\\\cybord\\\\img\\\\train\\\\*.jpg\"),\n",
    "                                test_size = 0.2)\n",
    "test = img_to_np(\"D:\\\\cybord\\\\img\\\\test\\\\*.jpg\")\n",
    "\n",
    "train = train.astype('float32') / 255.\n",
    "valid = valid.astype('float32') / 255.\n",
    "test = test.astype('float32') / 255.\n",
    "\n",
    "print(train.shape, valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [=] - 2s 46ms/step - loss: 0.0098\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0016\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0015\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0015\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0015\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0015\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0015\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0013\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0011\n",
      "50/50 [=] - 1s 18ms/step - loss: 0.0010\n",
      "50/50 [=] - 1s 18ms/step - loss: 9.3612e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 8.9447e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 8.4243e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 8.0602e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 7.8748e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 7.0712e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 6.7509e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 6.5657e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 6.0306e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 5.7306e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 5.4378e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 5.7455e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 5.0109e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 4.9476e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 4.8164e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 4.9392e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 4.4603e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 5.5762e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 4.3817e-04\n",
      "50/50 [=] - 1s 18ms/step - loss: 4.0036e-04\n"
     ]
    }
   ],
   "source": [
    "encoding_dim = 1024\n",
    "\n",
    "encoder_net = tf.keras.Sequential(\n",
    "  [\n",
    "      InputLayer(input_shape=(32, 32, 3)),\n",
    "      Conv2D(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Flatten(),\n",
    "      Dense(encoding_dim,)\n",
    "  ])\n",
    "\n",
    "decoder_net = tf.keras.Sequential(\n",
    "  [\n",
    "      InputLayer(input_shape=(encoding_dim,)),\n",
    "      Dense(4*4*128),\n",
    "      Reshape(target_shape=(4, 4, 128)),\n",
    "      Conv2DTranspose(256, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2DTranspose(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "# initialize outlier detector\n",
    "od = OutlierAE(threshold=0.015,  # threshold for outlier score\n",
    "                encoder_net=encoder_net,  # can also pass AE model instead\n",
    "                decoder_net=decoder_net,  # of separate encoder and decoder\n",
    "                )\n",
    "# train\n",
    "od.fit(train, epochs=30, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
